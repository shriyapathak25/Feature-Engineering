{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "ANS 1\n",
        "1. Parameter: A value that helps define or characterize something, like a setting or a constant.\n"
      ],
      "metadata": {
        "id": "KMjUYhBmEchS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANS 2\n",
        "1. Correlation: A measure of how two things are related or connected. If they tend to happen together, they're positively correlated. If one happens when the other doesn't, they're negatively correlated.\n",
        "\n",
        "2. Negative correlation: When two things tend to move in opposite directions. For example, when it rains, people are less likely to go outside (rain and outdoor activities are negatively correlated).\n"
      ],
      "metadata": {
        "id": "iuCz5KEvFj2T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANS 3\n",
        "A way to teach computers to learn from data, make decisions, and improve their performance on a task without being explicitly programmed.\n",
        "\n",
        "Main Components of Machine Learning\n",
        "1. Data: The information used to train the model.\n",
        "2. Model: The algorithm or set of rules used to make predictions.\n",
        "3. Loss Function: A measure of how well the model is doing.\n",
        "4. Optimization: The process of adjusting the model to minimize the loss.\n"
      ],
      "metadata": {
        "id": "_vPdYasIFqjP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANS 4\n",
        "Loss Value: A measure of how wrong the model's predictions are. A lower loss value means the model is doing better. It helps determine whether the model is good or no"
      ],
      "metadata": {
        "id": "7kBy7uSQFv1V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANS 5\n",
        "1. Continuous Variables: Can take any value within a range (e.g., height, weight).\n",
        "2. Categorical Variables: Can only take specific, distinct values (e.g., colors,countries)."
      ],
      "metadata": {
        "id": "1azsdBVXGoRE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANS 6\n",
        "Handling Categorical Variables\n",
        "1. Label Encoding: Assigning a unique integer value to each category.\n",
        "2. One-Hot Encoding (OHE): Creating new binary columns for each category.\n",
        "3. Ordinal Encoding: Assigning integer values to categories with a natural order.\n"
      ],
      "metadata": {
        "id": "_etYp0fSGvSI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANS 7\n",
        "Training and Testing a Dataset\n",
        "- Training: Using a portion of the data to teach the model to make predictions.\n",
        "- Testing: Evaluating the trained model on a separate portion of the data to estimate its performance.\n"
      ],
      "metadata": {
        "id": "yngb3RPDHX_j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANS 8\n",
        "\n",
        "- A Python module from scikit-learn library that provides various data preprocessing techniques, including:\n",
        "    - Scaling and normalization\n",
        "    - Encoding categorical variables\n",
        "    - Handling missing values\n"
      ],
      "metadata": {
        "id": "gaHE-pA3HiuB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANS 9 Test Set\n",
        "- A portion of the data (usually 20-30%) that is not used during training and is instead used to evaluate the model's performance.\n"
      ],
      "metadata": {
        "id": "kAV7gcupHpH1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANS 10\n",
        "Splitting Data in Python\n",
        "- Use train_test_split function from scikit-learn library:\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "Approaching a Machine Learning Problem\n",
        "1. Problem Definition: Clearly define the problem and identify the goals.\n",
        "2. Data Collection: Gather relevant data.\n",
        "3. Data Preprocessing: Clean, transform, and prepare the data.\n",
        "4. Model Selection: Choose a suitable algorithm.\n",
        "5. Model Training: Train the model using the training data.\n",
        "6. Model Evaluation: Evaluate the model using the test data.\n",
        "7. Model Tuning: Refine the model by adjusting hyperparameters.\n",
        "8. Deployment: Deploy the final model in a production-ready environment."
      ],
      "metadata": {
        "id": "H1V1SWTBH68n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANS 11\n",
        "Performing Exploratory Data Analysis (EDA) before fitting a model helps to:\n",
        "\n",
        "1. Understand the distribution of variables\n",
        "2. Identify missing values and outliers\n",
        "3. Visualize relationships between variables\n",
        "4. Detect potential issues with data quality\n"
      ],
      "metadata": {
        "id": "S-S0WlH9INfz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANS 12\n",
        "Correlation measures the strength and direction of a linear relationship between two variables.\n"
      ],
      "metadata": {
        "id": "pmix5UHhI204"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANS 13\n",
        "Negative correlation means that as one variable increases, the other decreases.\n"
      ],
      "metadata": {
        "id": "QFOCmlHCJDvo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANS 14\n",
        "You can use the corr() function from pandas library to calculate correlation between variables:\n",
        "\n",
        "import pandas as pd\n",
        "##### assume 'df' is a pandas DataFrame\n",
        "##### corr_matrix = df.corr()\n",
        "##### print(corr_matrix)\n"
      ],
      "metadata": {
        "id": "Vea1uRbSJPLg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANS 15 Causation\n",
        "Causation means that one variable directly affects the other.\n",
        "\n",
        "Correlation vs Causation Example\n",
        "Ice cream sales and number of people wearing shorts are positively correlated, but:\n",
        "\n",
        "- Eating ice cream doesn't cause people to wear shorts (correlation)\n",
        "- Warm weather causes both increased ice cream sales and people wearing shorts (causation)\n"
      ],
      "metadata": {
        "id": "zXD4BUdNKHMM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANS 16\n",
        "An optimizer is an algorithm used to minimize or maximize a function, typically used in machine learning to optimize model parameters.\n",
        "\n",
        "Types of Optimizers:\n",
        "\n",
        "1. Gradient Descent (GD): Updates parameters based on the gradient of the loss function. Example: optimizer = SGD(lr=0.01)\n",
        "2. Stochastic Gradient Descent (SGD): Updates parameters based on a single sample from the training data. Example: optimizer = SGD(lr=0.01)\n",
        "3. Adam: Adaptive learning rate optimizer that adjusts learning rate based on the magnitude of the gradient. Example: optimizer = Adam(lr=0.001)\n",
        "4. RMSprop: Similar to Adam, but only adjusts learning rate based on the magnitude of the gradient. Example: optimizer = RMSprop(lr=0.001)\n"
      ],
      "metadata": {
        "id": "01tiTzT-Kfou"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANS 17\n",
        "sklearn.linear_model is a module in scikit-learn library that provides implementation of various linear models, including Linear Regression, Logistic Regression, and Ridge Regression."
      ],
      "metadata": {
        "id": "a6y-G_VCK8JM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANS 18\n",
        "model.fit() is a method used to train a machine learning model. It takes in the training data and labels as arguments.\n",
        "\n",
        "Arguments:\n",
        "\n",
        "- X: Training data features\n",
        "- y: Training data labels\n"
      ],
      "metadata": {
        "id": "ZB7I3cHCLBYc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANS 19\n",
        "model.predict() is a method used to make predictions on new, unseen data. It takes in the test data features as an argument.\n",
        "\n",
        "Arguments:\n",
        "\n",
        "- X: Test data features\n"
      ],
      "metadata": {
        "id": "jb8r0Hw2LE6R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANS 20\n",
        "1. Continuous Variables: Variables that can take any value within a range or interval, including fractions and decimals. Examples: height, weight, temperature.\n",
        "2. Categorical Variables: Variables that can only take specific, distinct values. Examples: colors, countries, job titles."
      ],
      "metadata": {
        "id": "NkmDRgyKLIiC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANS 21 Feature scaling is a technique used to normalize the range of independent variables or features of data. It helps in Machine Learning by:\n",
        "\n",
        "- Improving model performance\n",
        "- Reducing the effect of dominant features\n",
        "- Enhancing model interpretability\n"
      ],
      "metadata": {
        "id": "2BBFbC8gLPBe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANS 22 We can perform scaling in Python using the StandardScaler or MinMaxScaler from the sklearn.preprocessing library.\n",
        "\n",
        "Example:\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaled_data = scaler.fit_transform(data)\n"
      ],
      "metadata": {
        "id": "jIoVbvP7LtoM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANS 23\n",
        "sklearn.preprocessing is a module in scikit-learn library that provides various data preprocessing techniques, including:\n",
        "\n",
        "- Scaling\n",
        "- Normalization\n",
        "- Encoding\n",
        "- Feature selection\n"
      ],
      "metadata": {
        "id": "pUawzA7OLvth"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANS 24 We can split data using the train_test_split function from the sklearn.model_selection library.\n",
        "\n",
        "Example:\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "d_iUavvyLzoL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANS 25 Data encoding is a technique used to convert categorical variables into numerical variables that can be processed by machine learning algorithms.\n",
        "\n",
        "Types of encoding:\n",
        "\n",
        "- Label Encoding: Assigns a unique integer value to each category.\n",
        "- One-Hot Encoding: Creates new binary columns for each category.\n",
        "- Ordinal Encoding: Assigns integer values to categories with a natural order"
      ],
      "metadata": {
        "id": "SJbn6hXcL6Sh"
      }
    }
  ]
}